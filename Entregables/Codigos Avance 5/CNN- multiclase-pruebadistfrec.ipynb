{"cells":[{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1164,"status":"ok","timestamp":1708892604100,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"},"user_tz":300},"id":"JUz-BNmh_nRW","outputId":"a3bb8beb-cda6-4fbe-f664-369190318a99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9472,"status":"ok","timestamp":1708892613568,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"},"user_tz":300},"id":"MG3Jkxkk_8hP","outputId":"77a620f1-7da2-4b6c-ebea-71385878eae6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sincnet_tensorflow in /usr/local/lib/python3.10/dist-packages (0.0.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from sincnet_tensorflow) (1.25.2)\n","Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.10/dist-packages (from sincnet_tensorflow) (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (1.60.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2->sincnet_tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->sincnet_tensorflow) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.2->sincnet_tensorflow) (3.2.2)\n"]}],"source":["!pip install sincnet_tensorflow"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708892613568,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"},"user_tz":300},"id":"zSY8ITPH_fR3"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Conv1D, LeakyReLU, BatchNormalization, Flatten, MaxPooling1D, Input\n","from sincnet_tensorflow import SincConv1D, LayerNorm\n","from sklearn.model_selection import train_test_split\n","import random\n","import pandas as pd\n","import librosa\n"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1582,"status":"ok","timestamp":1708892615147,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"},"user_tz":300},"id":"4xFLfaixhRw7","outputId":"2a4baef5-8428-417c-9c0c-9be74ab52385"},"outputs":[{"output_type":"stream","name":"stdout","text":["  AudioID AgeRange  Gender   Pathology  \\\n","0  651554    50-60  hombre  Laryngitis   \n","1   65902    50-60  hombre  Laryngitis   \n","2  652521    50-60  hombre  Laryngitis   \n","3   65818    50-60  hombre  Laryngitis   \n","4  652541    50-60  hombre  Laryngitis   \n","\n","                                       AudioFilePath  \n","0  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","1  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","2  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","3  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","4  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n"]}],"source":["# Cambia este path al lugar donde tienes tu archivo de texto y los audios\n","data_path = '/content/drive/MyDrive/TC5035 - Proyecto Integrador/Codigos de Prueba/datos aumentados por patologias/'\n","patologias_file = 'lista_pathological_info.txt'\n","\n","# Crear un DataFrame vacío\n","columns = ['AudioID', 'AgeRange', 'Gender', 'Pathology', 'AudioFilePath']\n","df_patologias = pd.DataFrame(columns=columns)\n","\n","# Lista de patologías de interés\n","patologias_interes = ['Dysphonie', 'Laryngitis', 'Rekurrensparese', 'Sano']\n","\n","# Leer el archivo de patologías y llenar el DataFrame\n","with open(os.path.join(data_path, patologias_file), 'r') as file:\n","    for line in file:\n","        parts = line.strip().split(' ')\n","        audio_id = parts[0]\n","        age_range = parts[1]\n","        gender = parts[2]\n","        # Suponiendo que la patología está al final y puede tener múltiples elementos separados por comas\n","        pathology = ' '.join(parts[3:])\n","        audio_file_path = os.path.join(data_path, f\"{audio_id}-phrase.wav\")\n","\n","        # Verificar y añadir cada patología de interés si está presente\n","        for pat in patologias_interes:\n","            if pat in pathology:\n","                # Crear un DataFrame para la nueva fila\n","                new_row_df = pd.DataFrame([{'AudioID': audio_id, 'AgeRange': age_range, 'Gender': gender, 'Pathology': pat, 'AudioFilePath': audio_file_path}])\n","\n","                # Usar pd.concat para concatenar el nuevo DataFrame con el existente\n","                df_patologias = pd.concat([df_patologias, new_row_df], ignore_index=True)\n","\n","print(df_patologias.head())\n"]},{"cell_type":"code","source":["df_patologias"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"S9CeB03PZDts","executionInfo":{"status":"ok","timestamp":1708892615147,"user_tz":300,"elapsed":8,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"f6e7e318-eede-46c4-d128-5c51abcadb07"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     AudioID AgeRange  Gender   Pathology  \\\n","0     651554    50-60  hombre  Laryngitis   \n","1      65902    50-60  hombre  Laryngitis   \n","2     652521    50-60  hombre  Laryngitis   \n","3      65818    50-60  hombre  Laryngitis   \n","4     652541    50-60  hombre  Laryngitis   \n","...      ...      ...     ...         ...   \n","1677    1280    50-60   mujer   Dysphonie   \n","1678     729    50-60   mujer   Dysphonie   \n","1679     674    50-60   mujer   Dysphonie   \n","1680    1471    50-60   mujer   Dysphonie   \n","1681     913    50-60   mujer   Dysphonie   \n","\n","                                          AudioFilePath  \n","0     /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","1     /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","2     /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","3     /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","4     /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","...                                                 ...  \n","1677  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","1678  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","1679  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","1680  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","1681  /content/drive/MyDrive/TC5035 - Proyecto Integ...  \n","\n","[1682 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-1ea23e7f-dee5-48fa-807b-52333ab81ac5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AudioID</th>\n","      <th>AgeRange</th>\n","      <th>Gender</th>\n","      <th>Pathology</th>\n","      <th>AudioFilePath</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>651554</td>\n","      <td>50-60</td>\n","      <td>hombre</td>\n","      <td>Laryngitis</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>65902</td>\n","      <td>50-60</td>\n","      <td>hombre</td>\n","      <td>Laryngitis</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>652521</td>\n","      <td>50-60</td>\n","      <td>hombre</td>\n","      <td>Laryngitis</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>65818</td>\n","      <td>50-60</td>\n","      <td>hombre</td>\n","      <td>Laryngitis</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>652541</td>\n","      <td>50-60</td>\n","      <td>hombre</td>\n","      <td>Laryngitis</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1677</th>\n","      <td>1280</td>\n","      <td>50-60</td>\n","      <td>mujer</td>\n","      <td>Dysphonie</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>1678</th>\n","      <td>729</td>\n","      <td>50-60</td>\n","      <td>mujer</td>\n","      <td>Dysphonie</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>1679</th>\n","      <td>674</td>\n","      <td>50-60</td>\n","      <td>mujer</td>\n","      <td>Dysphonie</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>1680</th>\n","      <td>1471</td>\n","      <td>50-60</td>\n","      <td>mujer</td>\n","      <td>Dysphonie</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","    <tr>\n","      <th>1681</th>\n","      <td>913</td>\n","      <td>50-60</td>\n","      <td>mujer</td>\n","      <td>Dysphonie</td>\n","      <td>/content/drive/MyDrive/TC5035 - Proyecto Integ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1682 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ea23e7f-dee5-48fa-807b-52333ab81ac5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1ea23e7f-dee5-48fa-807b-52333ab81ac5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1ea23e7f-dee5-48fa-807b-52333ab81ac5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-901e5e3d-c6e2-442d-8449-f86200cade27\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-901e5e3d-c6e2-442d-8449-f86200cade27')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-901e5e3d-c6e2-442d-8449-f86200cade27 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_patologias","summary":"{\n  \"name\": \"df_patologias\",\n  \"rows\": 1682,\n  \"fields\": [\n    {\n      \"column\": \"AudioID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1666,\n        \"samples\": [\n          \"52083\",\n          \"51054\",\n          \"52514\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AgeRange\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"50-60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"mujer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pathology\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Laryngitis\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AudioFilePath\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1666,\n        \"samples\": [\n          \"/content/drive/MyDrive/TC5035 - Proyecto Integrador/Codigos de Prueba/datos aumentados por patologias/52083-phrase.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":51}]},{"source":["# @title Pathology\n","\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","df_patologias.groupby('Pathology').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n","plt.gca().spines[['top', 'right',]].set_visible(False)"],"cell_type":"code","execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"jZNxc5GG2tDf","executionInfo":{"status":"ok","timestamp":1708892615849,"user_tz":300,"elapsed":707,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"6c421ff8-4ba7-4db2-a592-3a4769b5e491"}},{"cell_type":"code","source":["patologias_path = data_path + 'lista_pathological_info.txt'\n","\n","# Diccionario para mapear el nombre del archivo de audio a sus detalles\n","audio_details = {}\n","\n","with open(patologias_path, 'r') as file:\n","    for line in file:\n","        # Dividir la línea por espacios\n","        parts = line.strip().split(' ')\n","        audio_id = parts[0]\n","        gender = parts[2]\n","        pathologies = ' '.join(parts[3:]).split(' laryngitis')\n","        if len(pathologies) > 1:\n","            # Si tiene más de una patología, agregamos 'laryngitis' de nuevo al principio de cada patología adicional\n","            pathologies = [pathologies[0]] + ['laryngitis' + pathology for pathology in pathologies[1:]]\n","        # Nombre del archivo de audio\n","        audio_filename = f\"{audio_id}-phrase.wav\"\n","        # Guardar los detalles en el diccionario\n","        audio_details[audio_filename] = {'gender': gender, 'pathologies': pathologies}\n","\n","# Ejemplo para verificar algunos datos cargados\n","print(list(audio_details.items())[:5])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNxj7YbDe-zK","executionInfo":{"status":"ok","timestamp":1708892615849,"user_tz":300,"elapsed":6,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"db96c119-b184-435d-cb3d-365c8f301c02"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["[('651554-phrase.wav', {'gender': 'hombre', 'pathologies': ['Laryngitis']}), ('65902-phrase.wav', {'gender': 'hombre', 'pathologies': ['Laryngitis']}), ('652521-phrase.wav', {'gender': 'hombre', 'pathologies': ['Laryngitis']}), ('65818-phrase.wav', {'gender': 'hombre', 'pathologies': ['Laryngitis']}), ('652541-phrase.wav', {'gender': 'hombre', 'pathologies': ['Laryngitis']})]\n"]}]},{"cell_type":"code","source":["!pip install tftb\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTVdmsA41ZaN","executionInfo":{"status":"ok","timestamp":1708892629098,"user_tz":300,"elapsed":13252,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"7a8f8bbe-4317-4135-8dba-780480a7b45a"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tftb in /usr/local/lib/python3.10/dist-packages (0.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tftb) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tftb) (1.11.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tftb) (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tftb) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tftb) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tftb) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tftb) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tftb) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tftb) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tftb) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tftb) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->tftb) (1.16.0)\n"]}]},{"cell_type":"code","source":["import librosa\n","import numpy as np\n","import pywt\n","from tftb.processing import WignerVilleDistribution\n","#def load_audio_features(file_path):\n","#    audio, sample_rate = librosa.load(file_path, sr=None)\n","#    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n","#    mfccs_processed = np.mean(mfccs.T, axis=0)\n","#    return mfccs_processed\n","\n","\n","\n","# def load_audio_features(file_path):\n","#     audio, sample_rate = librosa.load(file_path,sr=4000) #sr=None)\n","\n","#     # Calcular MFCCs\n","#     mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n","#     mfccs_processed = np.mean(mfccs.T, axis=0)\n","\n","#     # Calcular características STFT\n","#     stft = np.abs(librosa.stft(audio))\n","#     stft_processed = np.mean(stft.T, axis=0)\n","\n","#     # Calcular características wavelet\n","#     # Usaremos la función Continuous Wavelet Transform (CWT) de PyWavelets\n","#     scales = np.arange(1, 128)  # Puedes ajustar estos valores\n","#     wavelet = 'cmor1.5-1.0'  # Coiflet wavelet, puedes elegir otro\n","#     coeffs, _ = pywt.cwt(audio, scales, wavelet, 1/sample_rate)\n","#     coeffs_processed = np.mean(np.abs(coeffs), axis=1)\n","\n","#     # Concatenar las características\n","#     features = np.concatenate((mfccs_processed, stft_processed, coeffs_processed))\n","\n","#     return features\n","\n","\n","def load_audio_features(file_path):\n","    audio, sample_rate = librosa.load(file_path, sr=4000)\n","\n","\n","\n","   #     # Calcular MFCCs\n","    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n","    mfccs_processed = np.mean(mfccs.T, axis=0)\n","\n","     # Calcular características STFT\n","    stft = np.abs(librosa.stft(audio))\n","    stft_processed = np.mean(stft.T, axis=0)\n","\n","     # Calcular características wavelet\n","     # Usaremos la función Continuous Wavelet Transform (CWT) de PyWavelets\n","    scales = np.arange(1, 128)  # Puedes ajustar estos valores\n","    wavelet = 'cmor1.5-1.0'  # Coiflet wavelet, puedes elegir otro\n","    coeffs, _ = pywt.cwt(audio, scales, wavelet, 1/sample_rate)\n","    coeffs_processed = np.mean(np.abs(coeffs), axis=1)\n","\n","    # Calcular características Wigner-Ville\n","\n","    #audio1 = audio.reshape(-1, 1)\n","    #wvd = WignerVilleDistribution(audio1)\n","    #wvd.run()\n","    #wvd_processed = np.mean(wvd.tfr, axis=1)\n","\n","    # Concatenar las características\n","    features = np.concatenate((mfccs_processed, stft_processed, coeffs_processed))#, wvd_processed))\n","\n","    return features\n","\n","\n","# Supongamos que quieres cargar las características de todos los archivos de audio y sus etiquetas\n","features = []\n","labels = []\n","\n","for audio_filename, details in  audio_details.items():\n","    file_path = data_path + audio_filename\n","    try:\n","        # Cargar características del audio\n","        audio_features = load_audio_features(file_path)\n","        features.append(audio_features)\n","        # Asumiendo que solo quieres la primera patología como etiqueta por simplicidad\n","        labels.append(details['pathologies'][0])\n","    except FileNotFoundError:\n","        print(f\"Archivo no encontrado: {file_path}\")\n","        continue\n","\n","# Ahora tienes 'features' y 'labels' listos para ser utilizados en entrenamiento de modelos\n"],"metadata":{"id":"N3ZfLns0VVZM","executionInfo":{"status":"ok","timestamp":1708893330377,"user_tz":300,"elapsed":701291,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1708893330378,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"},"user_tz":300},"id":"Ty1nNgIDhH_u","outputId":"b8234cdd-7adb-4bf1-a4e2-fe4599be3bf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-244.63492      69.20343      39.06667      30.845936     25.431341\n","   14.057586      3.7516239     2.0094612     4.568143      1.2806156\n","   -3.9028025    -3.3109932     0.87192166]\n"]}],"source":["\n","\n","# Función para cargar las características de un archivo de audio\n","def load_audio_features(file_path):\n","    audio, sample_rate = librosa.load(file_path, sr=None)\n","    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n","    mfccs_processed = np.mean(mfccs.T, axis=0)\n","    return mfccs_processed\n","\n","# Cargar características del primer archivo de audio en el DataFrame\n","first_audio_path = df_patologias.loc[0, 'AudioFilePath']\n","features = load_audio_features(first_audio_path)\n","print(features)"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708893330378,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"},"user_tz":300},"id":"iXx_iZrItXcP"},"outputs":[],"source":["import librosa\n","def cargar_audio(archivo_path):\n","    # Carga el archivo de audio usando librosa\n","    audio, _ = librosa.load(archivo_path, sr=50000)  # Asume una frecuencia de muestreo de 16000 Hz\n","\n","    # Asegúrate de que los datos estén en el formato correcto (8000 puntos de datos)\n","    if len(audio) <70000:\n","        # Si el audio es más corto, rellena con ceros\n","        audio = np.pad(audio, (0, 70000 - len(audio)))\n","    elif len(audio) > 70000:\n","        # Si el audio es más largo, truncalo\n","        audio = audio[:70000]\n","\n","    # Formatea los datos para que tengan la forma (8000, 1)\n","    audio = audio.reshape((70000, 1))\n","\n","    return audio"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jO8TKCtsjmTb","executionInfo":{"status":"ok","timestamp":1708893363477,"user_tz":300,"elapsed":33103,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"657a384a-b10d-4691-eac2-d47877f65a08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Características cargadas: (2316, 70000, 1)\n","Etiquetas cargadas: (2316,)\n"]}],"source":["# la ubicación de tus audios sanos\n","healthy_data_path = '/content/drive/.shortcut-targets-by-id/1MDEuAKtcvr_saVdZcC0ImDUZsJdQhf2U/TC5035 - Proyecto Integrador/Codigos de Prueba/Datasets/frase/Total/Sanos'\n","\n","# Obtener la lista de archivos de audio en la carpeta de audios sanos\n","healthy_audio_files = [f for f in os.listdir(healthy_data_path) if f.endswith('.wav')]\n","\n","# Listas para almacenar características y etiquetas\n","features_list = []\n","labels_list = []\n","\n","for index, row in df_patologias.iterrows():\n","    audio_file_path = row['AudioFilePath']\n","    pathology = row['Pathology']\n","\n","    try:\n","        # Cargar las características del audio usando la función cargar_audio\n","        features = cargar_audio(audio_file_path)\n","        # Añadir las características y la etiqueta a las listas\n","        features_list.append(features)\n","        labels_list.append(pathology)\n","    except Exception as e:\n","        print(f\"Error cargando {audio_file_path}: {e}\")\n","for file_name in healthy_audio_files:\n","    audio_file_path = os.path.join(healthy_data_path, file_name)\n","\n","    try:\n","        # Cargar las características del audio utilizando la función cargar_audio\n","        features = cargar_audio(audio_file_path)  # Usar cargar_audio en lugar de load_audio_features\n","        # Añadir las características a la lista\n","        features_list.append(features)\n","        # Añadir la etiqueta \"Sano\" a la lista de etiquetas\n","        labels_list.append(\"Sano\")\n","    except Exception as e:\n","        print(f\"Error cargando {audio_file_path}: {e}\")\n","# Convertir las listas en arrays de numpy para su uso en modelos de ML\n","features_array = np.array(features_list)\n","labels_array = np.array(labels_list)\n","\n","print(f\"Características cargadas: {features_array.shape}\")\n","print(f\"Etiquetas cargadas: {labels_array.shape}\")"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"sEURwn2Un9cm","executionInfo":{"status":"ok","timestamp":1708893363478,"user_tz":300,"elapsed":14,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}}},"outputs":[],"source":["X = features_array\n","y = labels_array"]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Asumiendo que 'y' es una lista o array de tus etiquetas (puede ser numérico o de texto)\n","# Ejemplo: y = ['Dysphonie', 'Laryngitis', 'Paralysis', 'sano', 'Dysphonie', ...]\n","\n","y_series = pd.Series(y)\n","\n","# Contar ocurrencias\n","label_counts = y_series.value_counts()\n","\n","print(\"Conteo de etiquetas por clase:\")\n","print(label_counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CvzC0p-IG27","executionInfo":{"status":"ok","timestamp":1708893363478,"user_tz":300,"elapsed":14,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"e57630ec-a22b-4cd2-ef16-6cae99e978cc"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Conteo de etiquetas por clase:\n","Sano               634\n","Rekurrensparese    574\n","Laryngitis         560\n","Dysphonie          548\n","dtype: int64\n"]}]},{"cell_type":"code","execution_count":61,"metadata":{"id":"gie8zVNmokiE","executionInfo":{"status":"ok","timestamp":1708893363696,"user_tz":300,"elapsed":231,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"23b6cad5-0890-4949-955a-789f54811514"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Codificar las etiquetas\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Opcional: Convertir las etiquetas numéricas a one-hot encoding\n","from sklearn.preprocessing import OneHotEncoder\n","onehot_encoder = OneHotEncoder(sparse=False)\n","y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(len(y_encoded), 1))\n"]},{"cell_type":"code","source":["import numpy as np\n","\n","# Suponiendo que y_encoded contiene tus etiquetas codificadas\n","unique_classes = np.unique(y_encoded)\n","num_classes = len(unique_classes)\n","print(f\"Número de clases únicas: {num_classes}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBjR51HTIp6N","executionInfo":{"status":"ok","timestamp":1708893363696,"user_tz":300,"elapsed":2,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"188d98ce-a79f-40b4-994e-e895f06b7411"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Número de clases únicas: 4\n"]}]},{"cell_type":"code","execution_count":63,"metadata":{"id":"ktnqmr-eZRrT","executionInfo":{"status":"ok","timestamp":1708893364091,"user_tz":300,"elapsed":397,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}}},"outputs":[],"source":["# Dividir datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"daYLK_A0qr5U","executionInfo":{"status":"ok","timestamp":1708893364091,"user_tz":300,"elapsed":3,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"2838ba01-c7d9-4124-e021-fbadd6794dd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Número de clases únicas: 4\n"]}],"source":["\n","# Convertir las etiquetas a una Serie de pandas\n","labels_series = pd.Series(y_encoded)\n","\n","# Contar el número de clases únicas\n","unique_classes = labels_series.unique()\n","num_classes = len(unique_classes)\n","print(f\"Número de clases únicas: {num_classes}\")"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HxGzyhoFp8U","executionInfo":{"status":"ok","timestamp":1708893366134,"user_tz":300,"elapsed":2044,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"6bfa02c2-332f-4474-f697-f0974af8a375"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," reshape_2 (Reshape)         (None, 70000, 1)          0         \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 4375, 64)          8320      \n","                                                                 \n"," layer_normalization_2 (Lay  (None, 4375, 64)          128       \n"," erNormalization)                                                \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 4375, 64)          0         \n","                                                                 \n"," max_pooling1d_2 (MaxPoolin  (None, 2187, 64)          0         \n"," g1D)                                                            \n","                                                                 \n"," flatten_2 (Flatten)         (None, 139968)            0         \n","                                                                 \n"," dense_6 (Dense)             (None, 256)               35832064  \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 256)               1024      \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 256)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 256)               65792     \n","                                                                 \n"," batch_normalization_5 (Bat  (None, 256)               1024      \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_8 (LeakyReLU)   (None, 256)               0         \n","                                                                 \n"," dense_8 (Dense)             (None, 4)                 1028      \n","                                                                 \n","=================================================================\n","Total params: 35909380 (136.98 MB)\n","Trainable params: 35908356 (136.98 MB)\n","Non-trainable params: 1024 (4.00 KB)\n","_________________________________________________________________\n"]}],"source":["\n","from tensorflow.keras import models, layers\n","\n","# Asumiendo que el tamaño de entrada es (70000, 1) como en el modelo original\n","\n","model = models.Sequential()\n","model.add(layers.Reshape((70000, 1), input_shape=(70000, 1)))  # Asegurar la forma de entrada correcta\n","\n","# Capa Conv1D\n","model.add(layers.Conv1D(filters=64, kernel_size=129, strides=16, padding='same', activation='relu'))\n","model.add(layers.LayerNormalization())  # Normalización de capa después de convolución\n","model.add(layers.LeakyReLU(alpha=0.2))\n","model.add(layers.MaxPooling1D(pool_size=2))\n","\n","# Puedes añadir más bloques de Conv1D -> Normalización -> Activación -> MaxPooling si es necesario\n","\n","# Aplanando los datos para la capa densa\n","model.add(layers.Flatten())\n","\n","# Primera capa densa con normalización y LeakyReLU\n","model.add(layers.Dense(256, activation='linear'))  # Activación lineal antes de la normalización\n","model.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n","model.add(layers.LeakyReLU(alpha=0.2))\n","\n","# Segunda capa densa, similar a la primera\n","model.add(layers.Dense(256, activation='linear'))\n","model.add(layers.BatchNormalization(momentum=0.05, epsilon=1e-5))\n","model.add(layers.LeakyReLU(alpha=0.2))\n","\n","# Capa de salida para clasificación multiclase\n","model.add(layers.Dense(4, activation='softmax'))  # 4 clases\n","\n","# Compilar el modelo\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',  # Asumiendo etiquetas categóricas (enteros)\n","              metrics=['accuracy'])\n","\n","# Resumen del modelo\n","model.summary()"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"hbwJjZNXBqLc","executionInfo":{"status":"ok","timestamp":1708894231665,"user_tz":300,"elapsed":865533,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1aa06e5-b683-416b-b7e9-c12cf71a57a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","47/47 [==============================] - 83s 2s/step - loss: 1.1252 - accuracy: 0.5557 - val_loss: 0.9561 - val_accuracy: 0.6631\n","Epoch 2/10\n","47/47 [==============================] - 93s 2s/step - loss: 0.3065 - accuracy: 0.9122 - val_loss: 1.0688 - val_accuracy: 0.6604\n","Epoch 3/10\n","47/47 [==============================] - 82s 2s/step - loss: 0.1124 - accuracy: 0.9764 - val_loss: 1.0806 - val_accuracy: 0.7358\n","Epoch 4/10\n","47/47 [==============================] - 87s 2s/step - loss: 0.0753 - accuracy: 0.9872 - val_loss: 0.9326 - val_accuracy: 0.7278\n","Epoch 5/10\n","47/47 [==============================] - 86s 2s/step - loss: 0.0554 - accuracy: 0.9872 - val_loss: 1.3772 - val_accuracy: 0.6900\n","Epoch 6/10\n","47/47 [==============================] - 81s 2s/step - loss: 0.0460 - accuracy: 0.9885 - val_loss: 1.5166 - val_accuracy: 0.6038\n","Epoch 7/10\n","47/47 [==============================] - 82s 2s/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 1.1326 - val_accuracy: 0.7385\n","Epoch 8/10\n","47/47 [==============================] - 82s 2s/step - loss: 0.0432 - accuracy: 0.9885 - val_loss: 1.1183 - val_accuracy: 0.7251\n","Epoch 9/10\n","47/47 [==============================] - 81s 2s/step - loss: 0.0327 - accuracy: 0.9892 - val_loss: 1.2723 - val_accuracy: 0.6765\n","Epoch 10/10\n","47/47 [==============================] - 82s 2s/step - loss: 0.0327 - accuracy: 0.9885 - val_loss: 1.1423 - val_accuracy: 0.7170\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a8d502d72e0>"]},"metadata":{},"execution_count":66}],"source":["# Suponiendo que y_train contiene etiquetas textuales\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","\n","# Ahora y_train_encoded contiene valores numéricos en lugar de cadenas\n","# Continúa con el entrenamiento utilizando y_train_encoded\n","model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"dv6rGI_LwAg7","executionInfo":{"status":"ok","timestamp":1708894231665,"user_tz":300,"elapsed":19,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"98fffe76-40de-490f-9e60-f954f2b1ba24"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(464, 70000, 1)"]},"metadata":{},"execution_count":67}],"source":["X_test.shape"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"xHRho3HYwSa-","executionInfo":{"status":"ok","timestamp":1708894231665,"user_tz":300,"elapsed":18,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"66616a12-5a00-41c2-e5ce-378f3d516ed5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(464,)"]},"metadata":{},"execution_count":68}],"source":["y_test.shape"]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","# Primero, convierte las etiquetas categóricas a numéricas\n","label_encoder = LabelEncoder()\n","y_numerical = label_encoder.fit_transform(y)\n","\n","# Ahora, convierte las etiquetas numéricas a one-hot encoding\n","y_one_hot = to_categorical(y_numerical)\n","\n","# Continúa con la división de los datos o cualquier otro paso siguiente\n","\n"],"metadata":{"id":"qoQvMx4pkFE_","executionInfo":{"status":"ok","timestamp":1708894231665,"user_tz":300,"elapsed":15,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["y_numerical[5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scMk9ihZm6o1","executionInfo":{"status":"ok","timestamp":1708894231665,"user_tz":300,"elapsed":14,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"6f2ae5ef-957e-4c26-9cc7-b14c30254f1a"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["y[5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"WbE1y693nHv6","executionInfo":{"status":"ok","timestamp":1708894231665,"user_tz":300,"elapsed":14,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"6eeb3d64-d925-4c07-d0a4-88b75bef7118"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Laryngitis'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Suponiendo que 'X' contiene tus datos de características\n","X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.3, random_state=42)"],"metadata":{"id":"oMSLsH4Lk1GF","executionInfo":{"status":"ok","timestamp":1708894232717,"user_tz":300,"elapsed":1056,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Hacer predicciones\n","predictions = model.predict(X_test)\n","\n","# Convertir predicciones y etiquetas verdaderas de one-hot a formato numérico\n","y_pred = np.argmax(predictions, axis=1)\n","y_test_labels = np.argmax(y_test, axis=1)\n","\n","# Calcular la matriz de confusión y otras métricas\n","cm = confusion_matrix(y_test_labels, y_pred)\n","print(\"Matriz de Confusión:\")\n","print(cm)\n","\n","report = classification_report(y_test_labels, y_pred, target_names=['Dysphonie', 'Laryngitis', 'Rekurrensparese', 'Sano'])\n","print(\"\\nMétricas de Clasificación:\")\n","print(report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfdOyiEnlAFK","executionInfo":{"status":"ok","timestamp":1708894253699,"user_tz":300,"elapsed":20984,"user":{"displayName":"Jorge Estivent Cruz Mahecha","userId":"09169606597223081379"}},"outputId":"431e7d17-2836-460a-8125-b2b6139ff7d0"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["22/22 [==============================] - 14s 641ms/step\n","Matriz de Confusión:\n","[[ 78   7  32  37]\n"," [  0 178   6   0]\n"," [  7   1 150   3]\n"," [ 19   2  14 161]]\n","\n","Métricas de Clasificación:\n","                 precision    recall  f1-score   support\n","\n","      Dysphonie       0.75      0.51      0.60       154\n","     Laryngitis       0.95      0.97      0.96       184\n","Rekurrensparese       0.74      0.93      0.83       161\n","           Sano       0.80      0.82      0.81       196\n","\n","       accuracy                           0.82       695\n","      macro avg       0.81      0.81      0.80       695\n","   weighted avg       0.81      0.82      0.81       695\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}